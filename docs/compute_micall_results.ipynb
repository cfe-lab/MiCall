{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps\n",
    "1. Download and install MiCall (MultiUseDocker branch, non-denovo) to a folder (`/local/repo`):\n",
    "\n",
    "```bash\n",
    "git clone git@github.com:cfe-lab/MiCall.git\n",
    "cd MiCall\n",
    "git checkout MultiUseDocker\n",
    "docker build --target dev -t micall .\n",
    "```\n",
    "\n",
    "If the `docker` command does not work try prefixing the command with `sudo` and/or ensuring the docker daemon is running (`sudo systemctl start docker` or `sudo service docker start`\n",
    "\n",
    "2. Collect data\n",
    "    1. Search for `SARS-COV-2` on NCBI SRA (https://www.ncbi.nlm.nih.gov/sra)\n",
    "    2. Download and install the SRA toolkit from NCBI (https://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?view=software)\n",
    "    3. Use the command (replace SRA number with your own) `fastq-dump --split-3 SRR11851926\n",
    "    4. This will yield 2 fastq files:\n",
    "        1. `SRR11851926_1.fastq`\n",
    "        2. `SRR11851926_2.fastq`\n",
    "    5. Put the two fastq files into a folder, let's call it `/path/to/fastq_files`\n",
    "    6. Repeat steps 2-5 until you have the desired number of samples\n",
    "    \n",
    "3. Run MiCall\n",
    "    1. Set up Docker\n",
    "    2. Run docker on your data folder\n",
    "    \n",
    "    ```bash\n",
    "    docker run --mount type=bind,source=/local/repo/MiCall,destination=/opt/micall --mount type=bind,source=/path/to/fastq_files,destination=/data micall folder\n",
    "    ```\n",
    "    3. You should have a `Results` folder in your `/path/to/fastq_files` that contains an `output` folder and a `scratch` folder. For this analysis we will focus on the `scratch` folder which should contain a folder for every sample you processed\n",
    "\n",
    "4. For each sample you downloaded, you must add an entry into the `/local/repo/MiCall/micall/utils/conseq_compare.py` script in the `MAPPING` variable. Add a 4-column (space-delimited) line in the format:\n",
    "    1. sample_name\n",
    "    2. sample_type\n",
    "    3. date\n",
    "    4. reference_name\n",
    "\n",
    "    e.g. `SRR11578349_1.fastq RNA-Seq 2020-05-04 EPI_ISL_427024`. \n",
    "\n",
    "5. You must also add the reference sequences to `/local/repo/MiCall/micall/tests/working/fetched_accessions.fasta`, most of them can be found by searching https://www.gisaid.org/ using the named reference in the SRA entry or other keywords from the SRA page (NRW-???). \n",
    "    1. Ensure that the sequence names n this fasta (e.g. `>ABC`) match column 4 of at least one entry in the `MAPPING` variable in step 4 (e.g. `X X X ABC`)\n",
    "    2. Set `conseq_path` to be the path to your `conseq_all.csv` file which will be in `/path/to/fastq_files/Results/output`\n",
    "\n",
    "6. Run `/local/repo/MiCall/micall/utils/conseq_compare.py`. For this step I used the script from the `dan_latest` branch: https://github.com/cfe-lab/MiCall/blob/dan_latest/micall/utils/conseq_compare.py\n",
    "\n",
    "```bash\n",
    "docker run --mount type=bind,source=/local/repo/MiCall,destination=/opt/micall -it --rm -w /opt/micall --entrypoint python micall -m micall.utils.conseq_compare\n",
    "```\n",
    "\n",
    "7. You should now have all the data necessary (check the sample folders in `/path/to/fastq_files/Results/scratch` for `data.csv` and `data_extended.csv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mixtures(row):\n",
    "    total = row['A'] + row['T'] + row['C'] + row['G']\n",
    "    thresh = 0.05 * total\n",
    "    alleles = {\n",
    "        'qpos': int(row['query.nuc.pos']),\n",
    "        'mixtures': {}\n",
    "    }\n",
    "    if row['coverage'] > 100:\n",
    "        for aa in ('A', 'C', 'T', 'G'):\n",
    "            if row[aa] > thresh:\n",
    "                alleles['mixtures'][aa] = round((row[aa] / row['coverage'] * 100), 2)\n",
    "    if len(alleles['mixtures']) > 1:\n",
    "        return alleles\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = Path('/path/to/fastq_files')\n",
    "ROOT = BASE / 'Results' / 'scratch'\n",
    "samples = os.listdir(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for sample in samples:\n",
    "    results[sample] = {}\n",
    "    data = ROOT / sample / 'data.csv'\n",
    "    data_extended = ROOT / sample / 'data_extended.csv'\n",
    "    nucs = ROOT / sample / 'nuc.csv'\n",
    "    conseq_all = ROOT / sample / 'conseq_all.csv'\n",
    "    \n",
    "    # Get length of conseq\n",
    "    conseqs = pd.read_csv(conseq_all)\n",
    "    conseq_len = len(conseqs[conseqs['region'].isnull()]['sequence'].iloc[0])\n",
    "    results[sample]['conseq_len'] = conseq_len\n",
    "    \n",
    "    # Get concordances\n",
    "    with open(data_extended) as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            results[sample]['concordance'] = row['concordance']\n",
    "    \n",
    "    # Get coverages\n",
    "    datafile = pd.read_csv(data)\n",
    "    for _type in ('mismatch', 'deletion', 'addition'):\n",
    "        info = datafile[\n",
    "            (datafile['type'] == _type)\n",
    "        ]\n",
    "        results[sample][_type] = info\n",
    "    \n",
    "    # Get mixtures\n",
    "    nucsfile = pd.read_csv(nucs)\n",
    "    nucsfile = nucsfile[\n",
    "        ~nucsfile['region'].str.contains('nsp')\n",
    "    ]\n",
    "    nucsfile['mixtures'] = nucsfile.apply(compute, axis=1)  # noqa\n",
    "    nucsfile = nucsfile[\n",
    "        ~nucsfile['mixtures'].isnull()\n",
    "    ]['mixtures']\n",
    "    results[sample]['mixtures'] = nucsfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the number of samples `N`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(results)\n",
    "print(f'We tested {N} samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the total number of nucleotides across all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_nucleotides = sum([results[x]['conseq_len'] for x in results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a dataframe of the mismatches only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatches = pd.concat(\n",
    "    [results[sample]['mismatch'] for sample in results]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the number of mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mismatches = len(mismatches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the number of unique mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_mismacthes = len(mismatches['sample'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match mixtures with mismatch positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_data = []\n",
    "for i,row in mismatches.iterrows():\n",
    "    thing = row.to_dict()\n",
    "    mixtures = results[row['sample']]['mixtures']\n",
    "    matching_mixture = None\n",
    "    for mix in mixtures:\n",
    "        if mix['qpos'] == row.pos:\n",
    "            matching_mixture = mix\n",
    "            break\n",
    "    if matching_mixture:\n",
    "        thing['match'] = True\n",
    "    else:\n",
    "        thing['match'] = False\n",
    "    mismatch_data.append(thing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print information on the mismatches per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatches_per_sample = [len(results[x]['mismatch']) for x in results]\n",
    "median = statistics.median(mismatches_per_sample)\n",
    "mean = round(statistics.mean(mismatches_per_sample), 3)\n",
    "q75, q25 = np.percentile(mismatches_per_sample, [75 ,25], interpolation='midpoint')\n",
    "iqr = q75 - q25\n",
    "\n",
    "\n",
    "print(f'median number of mismatches per sample: {median}')\n",
    "print(f'mean number of mismatches per sample: {mean}')\n",
    "print(f'25th percentile of mismatches: {q25}')\n",
    "print(f'75th percentile of mismatches: {q75}')\n",
    "print(f'iqr number of mismatches per sample: {iqr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print information on the concordances per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concord = [float(results[x]['concordance']) for x in results]\n",
    "median = statistics.median(concord)\n",
    "mean = round(statistics.mean(concord), 3)\n",
    "q75, q25 = np.percentile(concord, [75 ,25], interpolation='midpoint')\n",
    "iqr = round(q75 - q25, 4)\n",
    "\n",
    "\n",
    "print(f'median concordance: {median}')\n",
    "print(f'mean concordance: {mean}')\n",
    "print(f'25th percentile: {q25}')\n",
    "print(f'75th percentile: {q75}')\n",
    "print(f'iqr concordance: {iqr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print information on the number of mixtures per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixnums = [len(results[s]['mixtures']) for s in results]\n",
    "median = statistics.median(mixnums)\n",
    "mean = round(statistics.mean(mixnums), 3)\n",
    "q75, q25 = np.percentile(mixnums, [75 ,25], interpolation='midpoint')\n",
    "iqr = q75 - q25\n",
    "\n",
    "print(f'total number of mixtures: {sum(mixnums)}')\n",
    "print(f'median number of mixtures: {median}')\n",
    "print(f'mean number of mixtures: {mean}')\n",
    "print(f'25th percentile: {q25}')\n",
    "print(f'75th percentile: {q75}')\n",
    "print(f'iqr number of mixtures: {iqr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print information on the minor frequency alleles (If a position has 60% A and 40% T, the minor frequency allele is T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minor_freqs = []\n",
    "for sample in results:\n",
    "    _min = None\n",
    "    for mix in results[sample]['mixtures']:\n",
    "        if not _min:\n",
    "            _min = min(mix['mixtures'].items(), key=itemgetter(1))\n",
    "            continue\n",
    "        mymin = min(mix['mixtures'].items(), key=itemgetter(1))\n",
    "        if mymin < _min:\n",
    "            _min = mymin\n",
    "    if _min:\n",
    "        minor_freqs.append(_min)\n",
    "        \n",
    "minor_freqs = [x[1] for x in minor_freqs]\n",
    "median = round(statistics.median(minor_freqs), 2)\n",
    "mean = round(statistics.mean(minor_freqs), 2)\n",
    "q75, q25 = np.percentile(minor_freqs, [75 ,25], interpolation='midpoint')\n",
    "iqr = round(q75 - q25, 4)\n",
    "\n",
    "print(f'median minor allele frequency: {median}')\n",
    "print(f'mean minor allele frequency: {mean}')\n",
    "print(f'25th percentile: {q25}')\n",
    "print(f'75th percentile: {q75}')\n",
    "print(f'iqr minor allele frequency: {iqr}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
